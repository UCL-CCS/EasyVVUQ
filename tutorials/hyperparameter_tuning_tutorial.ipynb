{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c43ea9",
   "metadata": {},
   "source": [
    "## Tuning the hyperparameters of a neural network using EasyVVUQ\n",
    "\n",
    "In this tutorial we will use the EasyVVUQ `GridSampler` to perform a grid search on the hyperparameters of a simple Keras neural network model, trained to recognize hand-written digits. This is the famous MNIST data set, of which 4 input features (of size 28 x 28) are show below. These are fed into a standard feed-forward neural network, which will predict the label 0-9.\n",
    "\n",
    "**Note**: This tutorial always runs on the localhost. One possibility of performing the grid search on a remote supercomputer involves the use of FabSim, see the `hyperparameter_tuning_tutorial_with_fabsim.ipynb` notebook tutorial.\n",
    "\n",
    "The (Keras) neural network script is located in `mnist/keras_mnist.template`, which will form the input template for the EasyVVUQ encoder. We will assume you are familiar with the basic EasyVVUQ building blocks. If not, you can look at the [basic tutorial](https://github.com/UCL-CCS/EasyVVUQ/blob/dev/tutorials/basic_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83545e38",
   "metadata": {},
   "source": [
    "![](mnist/mnist_feats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf467821",
   "metadata": {},
   "source": [
    "We need EasyVVUQ, TensorFlow and the TensorFlow data sets to execute this tutorial. If you need to install these, uncomment the corresponding line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f7ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install easyvvuq\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7347053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyvvuq as uq\n",
    "import os\n",
    "import numpy as np\n",
    "from easyvvuq.actions import CreateRunDirectory, Encode, Decode, ExecuteLocal, Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22672c4c",
   "metadata": {},
   "source": [
    "We now set some flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52064503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work directory, where the EasyVVUQ directory will be placed\n",
    "WORK_DIR = '/tmp'\n",
    "# target output filename generated by the code\n",
    "TARGET_FILENAME = 'output.csv'\n",
    "# EasyVVUQ campaign name\n",
    "CAMPAIGN_NAME = 'grid_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae997f",
   "metadata": {},
   "source": [
    "As is standard in EasyVVUQ, we now define the parameter space. In this case these are 4 hyperparameters. There is one hidden layer with `n_neurons` neurons, a Dropout layer after the input and hidden layer, with dropout probability `dropout_prob_in` and `dropout_prob_hidden` respectively. We made the `learning_rate` tuneable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3a8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"n_neurons\"] = {\"type\":\"integer\", \"default\": 32}\n",
    "params[\"dropout_prob_in\"] = {\"type\":\"float\", \"default\": 0.0}\n",
    "params[\"dropout_prob_hidden\"] = {\"type\":\"float\", \"default\": 0.0}\n",
    "params[\"learning_rate\"] = {\"type\":\"float\", \"default\": 0.001}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41214c",
   "metadata": {},
   "source": [
    "These 4 hyperparameter appear as flags in the input template `mnist/keras_mnist.template`. Typically this is generated from an input file used by some simualtion code. In this case however, `mnist/keras_mnist.template` is directly our Python script, with the hyperparameters replaced by flags. For instance:\n",
    "\n",
    "```python\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dropout($dropout_prob_in),\n",
    "  tf.keras.layers.Dense($n_neurons, activation='relu'),\n",
    "  tf.keras.layers.Dropout($dropout_prob_hidden),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "```\n",
    "\n",
    "is simply the neural network construction part with flags for the dropout probabilities and the number of neurons in the hidden layer. The encoder reads the flags and replaces them with numeric values, and it subsequently writes the corresponding `target_filename=hyper_param_tune.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed08818",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = uq.encoders.GenericEncoder('./mnist/keras_mnist.template', target_filename='hyper_param_tune.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02644574",
   "metadata": {},
   "source": [
    "What follows are standard steps in setting up an EasyVVUQ Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10d571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the runs locally\n",
    "execute = ExecuteLocal('python3 hyper_param_tune.py')\n",
    "\n",
    "# decode the output CSV files, with stored training and test accuracy values\n",
    "output_columns = [\"accuracy_train\", \"accuracy_test\"]\n",
    "decoder = uq.decoders.SimpleCSV(target_filename=TARGET_FILENAME, output_columns=output_columns)\n",
    "\n",
    "# actions are 1) create run dirs, 2) encode input template, 3) execute runs, 4) decode output files\n",
    "actions = Actions(CreateRunDirectory(root='/tmp', flatten=True), Encode(encoder), execute, Decode(decoder))\n",
    "\n",
    "# create the EasyVVUQ main campaign object\n",
    "campaign = uq.Campaign(\n",
    "    name=CAMPAIGN_NAME,\n",
    "    work_dir=WORK_DIR,\n",
    ")\n",
    "\n",
    "# add the param definitions and actions to the campaign\n",
    "campaign.add_app(\n",
    "    name=CAMPAIGN_NAME,\n",
    "    params=params,\n",
    "    actions=actions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbba5f8",
   "metadata": {},
   "source": [
    "As with the uncertainty-quantification (UQ) samplers, the `vary` is used to select which of the `params` we actually vary. Unlike the UQ samplers we do not specify an input probability distribution. This being a grid search, we simply specify a list of values for each hyperparameter. Parameters not in `vary`, but with a flag in the template, will be given the default value specified in `params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3247048",
   "metadata": {},
   "outputs": [],
   "source": [
    "vary = {\"n_neurons\": [64, 128], \"learning_rate\": [0.005, 0.01, 0.015]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e912c",
   "metadata": {},
   "source": [
    "**Note:** we are mixing integer and floats in the `vary` dict. Other data types (string, boolean) can also be used.\n",
    "\n",
    "The `vary` dict is passed to the `Grid_Sampler`. As can be seen, it created a tensor product of all 1D points specified in `vary`. If a single tensor product is not useful (e.g. because it creates combinations of parameters that do not makes sense), you can also pass a list of different `vary` dicts. For even more flexibility you can also write the required parameter combinations to a CSV file, and pass it to the `CSV_Sampler` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e62d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 points:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[64, 0.005],\n",
       "        [64, 0.01],\n",
       "        [64, 0.015],\n",
       "        [128, 0.005],\n",
       "        [128, 0.01],\n",
       "        [128, 0.015]], dtype=object)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the Grid Sampler\n",
    "sampler = uq.sampling.Grid_Sampler(vary)\n",
    "\n",
    "# Associate the sampler with the campaign\n",
    "campaign.set_sampler(sampler)\n",
    "\n",
    "# print the points\n",
    "print(\"There are %d points:\" % (sampler.n_samples()))\n",
    "sampler.points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c39b4b",
   "metadata": {},
   "source": [
    "Run the `actions` (create directories with `hyper_param_tune.py` files in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 11:34:46.627885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:46.628054: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:46.630651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:46.632733: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:46.635383: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:46.637862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:47.056973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:47.056973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:47.057003: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 11:34:47.057002: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 11:34:47.057004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:47.057004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:47.057011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:47.057011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:47.057026: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 11:34:47.057026: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 11:34:47.057032: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 11:34:47.057032: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 11:34:48.728698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.728836: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.728853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-02 11:34:48.735720: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.735854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.735872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-02 11:34:48.747918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.747999: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.748009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-02 11:34:48.760968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.761089: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.761108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-02 11:34:48.803344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.803468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.803486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-02 11:34:48.828321: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.828443: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:48.828462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 11:34:52.172878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:52.173245: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-02 11:34:52.173292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wouter-XPS-13-7390): /proc/driver/nvidia/version does not exist\n",
      "2023-03-02 11:34:52.175002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:52.177382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:52.177406: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-02 11:34:52.177426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wouter-XPS-13-7390): /proc/driver/nvidia/version does not exist\n",
      "2023-03-02 11:34:52.177712: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:52.179983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:52.179983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:52.180013: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-02 11:34:52.180013: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-02 11:34:52.180044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wouter-XPS-13-7390): /proc/driver/nvidia/version does not exist\n",
      "2023-03-02 11:34:52.180049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wouter-XPS-13-7390): /proc/driver/nvidia/version does not exist\n",
      "2023-03-02 11:34:52.180416: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:52.180415: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:52.188145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:52.188183: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-02 11:34:52.188216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wouter-XPS-13-7390): /proc/driver/nvidia/version does not exist\n",
      "2023-03-02 11:34:52.188602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:34:52.193807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-02 11:34:52.193845: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-02 11:34:52.193878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wouter-XPS-13-7390): /proc/driver/nvidia/version does not exist\n",
      "2023-03-02 11:34:52.194312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "Epoch 1/6\n",
      "Epoch 1/6\n",
      "Epoch 1/6\n",
      "Epoch 1/6\n",
      "Epoch 1/6\n",
      "469/469 [==============================] - 15s 13ms/step - loss: 0.4033 - sparse_categorical_accuracy: 0.8792 - val_loss: 0.2163 - val_sparse_categorical_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 15s 9ms/step - loss: 0.4464 - sparse_categorical_accuracy: 0.8710 - val_loss: 0.2590 - val_sparse_categorical_accuracy: 0.9264\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 15s 13ms/step - loss: 0.5436 - sparse_categorical_accuracy: 0.8448 - val_loss: 0.2959 - val_sparse_categorical_accuracy: 0.9169\n",
      "469/469 [==============================] - 16s 14ms/step - loss: 0.4242 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.2251 - val_sparse_categorical_accuracy: 0.9334\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 16s 14ms/step - loss: 0.3825 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.2041 - val_sparse_categorical_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 16s 14ms/step - loss: 0.5121 - sparse_categorical_accuracy: 0.8543 - val_loss: 0.2868 - val_sparse_categorical_accuracy: 0.9208\n",
      "296/469 [=================>............] - ETA: 0s - loss: 0.2019 - sparse_categorical_accuracy: 0.9404Epoch 2/6\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2190 - sparse_categorical_accuracy: 0.9385 - val_loss: 0.1947 - val_sparse_categorical_accuracy: 0.9430\n",
      "243/469 [==============>...............] - ETA: 1s - loss: 0.2207 - sparse_categorical_accuracy: 0.9359Epoch 3/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1926 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.1692 - val_sparse_categorical_accuracy: 0.9502\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2056 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.1634 - val_sparse_categorical_accuracy: 0.9507\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1765 - sparse_categorical_accuracy: 0.9489 - val_loss: 0.1405 - val_sparse_categorical_accuracy: 0.9589\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2690 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.2342 - val_sparse_categorical_accuracy: 0.9324\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1725 - sparse_categorical_accuracy: 0.9514 - val_loss: 0.1574 - val_sparse_categorical_accuracy: 0.9550\n",
      " 84/469 [====>.........................] - ETA: 2s - loss: 0.2292 - sparse_categorical_accuracy: 0.9323Epoch 4/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1440 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.1253 - val_sparse_categorical_accuracy: 0.9631\n",
      "Epoch 4/6\n",
      "221/469 [=============>................] - ETA: 1s - loss: 0.1635 - sparse_categorical_accuracy: 0.9525Epoch 3/6\n",
      "113/469 [======>.......................] - ETA: 1s - loss: 0.1428 - sparse_categorical_accuracy: 0.9583Epoch 2/6\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9578\n",
      "455/469 [============================>.] - ETA: 0s - loss: 0.1411 - sparse_categorical_accuracy: 0.9602Epoch 4/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2198 - sparse_categorical_accuracy: 0.9381 - val_loss: 0.1971 - val_sparse_categorical_accuracy: 0.9432\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1407 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9623\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.1115 - val_sparse_categorical_accuracy: 0.9675\n",
      "437/469 [==========================>...] - ETA: 0s - loss: 0.2782 - sparse_categorical_accuracy: 0.9216Epoch 5/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9632 - val_loss: 0.1169 - val_sparse_categorical_accuracy: 0.9652\n",
      " 58/469 [==>...........................] - ETA: 1s - loss: 0.1079 - sparse_categorical_accuracy: 0.9674Epoch 4/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2760 - sparse_categorical_accuracy: 0.9222 - val_loss: 0.2362 - val_sparse_categorical_accuracy: 0.9323\n",
      "361/469 [======================>.......] - ETA: 0s - loss: 0.1000 - sparse_categorical_accuracy: 0.9704Epoch 4/6\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1241 - sparse_categorical_accuracy: 0.9643 - val_loss: 0.1146 - val_sparse_categorical_accuracy: 0.9661\n",
      "Epoch 5/6\n",
      "109/469 [=====>........................] - ETA: 1s - loss: 0.2055 - sparse_categorical_accuracy: 0.9414Epoch 5/6\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1003 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1062 - val_sparse_categorical_accuracy: 0.9665\n",
      "147/469 [========>.....................] - ETA: 1s - loss: 0.1988 - sparse_categorical_accuracy: 0.9439Epoch 6/6\n",
      "119/469 [======>.......................] - ETA: 1s - loss: 0.1241 - sparse_categorical_accuracy: 0.9641Epoch 3/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1030 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.1046 - val_sparse_categorical_accuracy: 0.9687\n",
      " 67/469 [===>..........................] - ETA: 2s - loss: 0.2337 - sparse_categorical_accuracy: 0.9356Epoch 5/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1873 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.1769 - val_sparse_categorical_accuracy: 0.9504\n",
      "248/469 [==============>...............] - ETA: 1s - loss: 0.0810 - sparse_categorical_accuracy: 0.9773Epoch 5/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1245 - val_sparse_categorical_accuracy: 0.9628\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0867 - sparse_categorical_accuracy: 0.9755 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9702\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1038 - sparse_categorical_accuracy: 0.9709 - val_loss: 0.1101 - val_sparse_categorical_accuracy: 0.9670\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2256 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.2024 - val_sparse_categorical_accuracy: 0.9425\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9758 - val_loss: 0.0951 - val_sparse_categorical_accuracy: 0.9703\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9791\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1070 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9682\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1628 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.1559 - val_sparse_categorical_accuracy: 0.9545\n",
      "Epoch 6/6\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 0.0950 - sparse_categorical_accuracy: 0.9729Epoch 4/6\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9702\n",
      " 84/469 [====>.........................] - ETA: 1s - loss: 0.2051 - sparse_categorical_accuracy: 0.9418Epoch 6/6\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9735\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0900 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.0938 - val_sparse_categorical_accuracy: 0.9720\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1441 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.1390 - val_sparse_categorical_accuracy: 0.9595\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9682\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1951 - sparse_categorical_accuracy: 0.9449 - val_loss: 0.1784 - val_sparse_categorical_accuracy: 0.9480\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9797 - val_loss: 0.0847 - val_sparse_categorical_accuracy: 0.9726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1309 - sparse_categorical_accuracy: 0.9635\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1390 - sparse_categorical_accuracy: 0.9595\n",
      "460/469 [============================>.] - ETA: 0s - loss: 0.1721 - sparse_categorical_accuracy: 0.9512"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# execute the defined actions #\n",
    "###############################\n",
    "\n",
    "campaign.execute().collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = campaign.get_collation_result()\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e62a8c",
   "metadata": {},
   "source": [
    "Display the hyperparameters with the maximum test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters with %.2f%% test accuracy:\" % (data_frame['accuracy_test'].max().values * 100,))\n",
    "data_frame.loc[data_frame['accuracy_test'].idxmax()][vary.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9647a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
